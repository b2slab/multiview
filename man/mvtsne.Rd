% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mvtsne.R
\name{mvtsne}
\alias{mvtsne}
\title{Multiview tSNE using an expert opinion pooling on the input probability matrices}
\usage{
mvtsne(X, k = 2, initial_dims = 30, perplexity = 30, max_iter = 1000,
  min_cost = 0, epoch_callback = NULL, whiten = TRUE, epoch = 100)
}
\arguments{
\item{X}{A list of R matrices or "dist" objects, where each matrix/dist is one of the views of the dataset.}

\item{k}{The desired dimension of the resulting embedding.}

\item{initial_dims}{Number of dimensions to use in the reduction method.}

\item{perplexity}{This perplexity parameter is roughly equivalent to the optimal number of neighbours.}

\item{max_iter}{Maximum number of iterations to perform.}

\item{min_cost}{The minimum cost value (error) to stop iterations.}

\item{epoch_callback}{A callback function to be called after each epoch (which is a number of iterations controlled
parameter \code{epoch}, see next).}

\item{whiten}{A boolean value indicating if the data matrices should be whitened.}

\item{epoch}{The number of iterations between update messages.}
}
\value{
A list with two elements: \code{embedding} with the k-dimensional embedding of the input samples, and
        \code{weights} with the weights associated to each input data view.
}
\description{
Given a list of of input views and other parameters, \code{mvtsne} computes a neighbouring probability matrix
for each input view, then finds the optimal set of weights to combine these matrices using a log-linear pool,
and applies the pooled probability matrix as input to the standard tSNE procedure, where the probability matrix
of the output space is adjusted to the pooled probability matrix using Kullback-Liebler divergence.
}
\note{
All input views must have the same number of samples (rows).
}
\examples{
m1 <- iris[, 1:2]
m2 <- iris[, 3:4]
mvtsne(list(m1, m2), k = 2)

}
